{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTQHvoJcQsFy"
   },
   "source": [
    "#Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVu9CTktX9II"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "from skimage import filters\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULNUNPabQ2xm"
   },
   "source": [
    "#Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSL3zGckStIt"
   },
   "source": [
    "Pembagian dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVL5lznAclSV"
   },
   "outputs": [],
   "source": [
    "classLabels = ['1000', '10000', '100000', '2000', '20000', '5000', '50000']\n",
    "def transferBetweenFolders(source, dest, splitRate):   \n",
    "    global sourceFiles\n",
    "    sourceFiles=os.listdir(source)\n",
    "    if(len(sourceFiles)!=0):\n",
    "        transferFileNumbers=int(len(sourceFiles)*splitRate)\n",
    "        transferIndex=random.sample(range(0, len(sourceFiles)), transferFileNumbers)\n",
    "        for eachIndex in transferIndex:\n",
    "            shutil.move(source+str(sourceFiles[eachIndex]), dest+str(sourceFiles[eachIndex]))\n",
    "    else:\n",
    "        print(\"No file moved. Source empty!\")\n",
    "        \n",
    "def transferAllClassBetweenFolders(source, dest, splitRate):\n",
    "    for label in classLabels:\n",
    "        transferBetweenFolders('/content/drive/My Drive/TA/splitdata'+'/'+source+'/'+label+'/', \n",
    "                               '/content/drive/My Drive/TA/splitdata'+'/'+dest+'/'+label+'/', \n",
    "                               splitRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrUWMvhKc-aH"
   },
   "outputs": [],
   "source": [
    "# os.chdir('/content/drive/My Drive/TA/splitdata')\n",
    "# First, check if test folder is empty or not, if not transfer all existing files to train\n",
    "# transferAllClassBetweenFolders('validation', 'train', 1.0)\n",
    "# Now, split some part of train data into the test folders.\n",
    "transferAllClassBetweenFolders('train', 'validation', 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plXbzCp2RRFs"
   },
   "source": [
    "Fungsi metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STlfGtWCioSN"
   },
   "outputs": [],
   "source": [
    "def my_metrics(y_true, y_pred):\n",
    "    accuracy=accuracy_score(y_true, y_pred)\n",
    "    precision=precision_score(y_true, y_pred,average='weighted')\n",
    "    f1Score=f1_score(y_true, y_pred, average='weighted') \n",
    "    print(\"Accuracy  : {}\".format(accuracy))\n",
    "    print(\"Precision : {}\".format(precision))\n",
    "    print(\"f1Score : {}\".format(f1Score))\n",
    "    cm=confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    return accuracy, precision, f1Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQNeke6BST8l"
   },
   "source": [
    "Prepare lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IlHpKd5cD4Y"
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "\n",
    "def prepareNameWithLabels(folderName):\n",
    "    sourceFiles=os.listdir('/content/drive/My Drive/TA/splitdata/train/'+folderName)\n",
    "    for val in sourceFiles:\n",
    "        X.append(val)\n",
    "        if(folderName==classLabels[0]):\n",
    "            Y.append(0)\n",
    "        elif(folderName==classLabels[1]):\n",
    "            Y.append(1)\n",
    "        elif(folderName==classLabels[2]):\n",
    "            Y.append(2)\n",
    "        elif(folderName==classLabels[3]):\n",
    "            Y.append(3)\n",
    "        elif(folderName==classLabels[4]):\n",
    "            Y.append(4)\n",
    "        elif(folderName==classLabels[5]):\n",
    "            Y.append(5)\n",
    "        else:\n",
    "            Y.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwN7_E6Bivb8"
   },
   "outputs": [],
   "source": [
    "# Organize file names and class labels in X and Y variables\n",
    "for label in classLabels:\n",
    "  prepareNameWithLabels(label)      \n",
    "\n",
    "X=np.asarray(X)\n",
    "Y=np.asarray(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCnZbAwPS8qq"
   },
   "source": [
    "Preprocess image function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-s4gSTdFYHqJ"
   },
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "  # image = filters.median(image)\n",
    "  # p2, p98 = np.percentile(image, (2, 98))\n",
    "  # image = exposure.rescale_intensity(image, in_range=(p2, p98))\n",
    "  # image = tf.cast(image, tf.float32)\n",
    "  # image = tf.image.resize(image, (224, 224))\n",
    "  # image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "  # image = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
    "  # image = filters.gaussian(image, sigma=1)\n",
    "  \n",
    "  # image = image[None, ...]\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdbmfQU7TFIU"
   },
   "source": [
    "Image data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RW1vdvdkYIfl"
   },
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator(\n",
    "    # width_shift_range= 0.1, \n",
    "    # height_shift_range= 0.1,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.2,\n",
    "    rescale=1./255,\n",
    "    # preprocessing_function = preprocess,\n",
    "    # shear_range = 0.2,\n",
    "    # fill_mode = 'nearest'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJTj55H7TOQx"
   },
   "source": [
    "#Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULC3Y_vcTQes"
   },
   "source": [
    "Create and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wAs0WmWpjV0b",
    "outputId": "9f2e2bc3-31d3-403d-eb3f-b697f0dd6b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# CREATE NEW MODEL\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    # input_shape=(224, 224, 3),\n",
    "    input_shape=(312, 416, 3),  \n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    ")\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model, \n",
    "  tf.keras.layers.GlobalMaxPooling2D(),\n",
    "  tf.keras.layers.Dropout(0.1),\n",
    "  tf.keras.layers.Dense(512, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(7, activation='softmax'),\n",
    "])\n",
    "\n",
    "# COMPILE NEW MODEL\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.SGD(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-Tzd6ftTewU"
   },
   "source": [
    "Train with K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c5zbGjxyYC9w",
    "outputId": "1fdf71a9-b781-47d9-901d-2bc4bfd55ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file moved. Source empty!\n",
      "No file moved. Source empty!\n",
      "No file moved. Source empty!\n",
      "No file moved. Source empty!\n",
      "No file moved. Source empty!\n",
      "No file moved. Source empty!\n",
      "Results for fold 1\n",
      "Found 999 images belonging to 7 classes.\n",
      "Found 667 images belonging to 7 classes.\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 175s 6s/step - loss: 1.1766 - accuracy: 0.8318 - val_loss: 1.6113 - val_accuracy: 0.3718\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - ETA: 0s - loss: 1.0158 - accuracy: 0.8989"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True)\n",
    "kf.get_n_splits(X, Y)\n",
    "    \n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "TRAINING_ACCURACY = []\n",
    "TRAINING_LOSS = []\n",
    "\n",
    "fold_var = 0\n",
    "\n",
    "train_path = '/content/drive/My Drive/TA/splitdata/train'\n",
    "val_path = '/content/drive/My Drive/TA/splitdata/validation'\n",
    "\n",
    "for train_index, val_index in kf.split(X, Y):\n",
    "  #First cut all images from validation to train (if any exists)\n",
    "  transferAllClassBetweenFolders('validation', 'train', 1.0)\n",
    "  fold_var += 1\n",
    "  print(\"Results for fold\",fold_var)\n",
    "  X_train, X_val = X[train_index], X[val_index]\n",
    "  Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "  # Move validation images of this fold from train folder to the validation folder\n",
    "  for eachIndex in range(len(X_val)):\n",
    "      classLabel=''\n",
    "      if(Y_val[eachIndex]==0):\n",
    "          classLabel=classLabels[0]\n",
    "      elif(Y_val[eachIndex]==1):\n",
    "          classLabel=classLabels[1]\n",
    "      elif(Y_val[eachIndex]==2):\n",
    "          classLabel=classLabels[2]\n",
    "      elif(Y_val[eachIndex]==3):\n",
    "          classLabel=classLabels[3]\n",
    "      elif(Y_val[eachIndex]==4):\n",
    "          classLabel=classLabels[4]\n",
    "      elif(Y_val[eachIndex]==5):\n",
    "          classLabel=classLabels[5]\n",
    "      else:\n",
    "          classLabel=classLabels[6]   \n",
    "      #Then, copy the validation images to the validation folder\n",
    "      shutil.move('/content/drive/My Drive/TA/splitdata/train/'+classLabel+'/'+X_val[eachIndex], \n",
    "                  '/content/drive/My Drive/TA/splitdata/validation/'+classLabel+'/'+X_val[eachIndex])\n",
    "\n",
    "  train_generator = image_datagen.flow_from_directory(train_path,\n",
    "                                                      target_size=(312, 416),\n",
    "                                                      # target_size=(224, 224), \n",
    "                                                      batch_size=32,\n",
    "                                                      shuffle=True,\n",
    "                                                      subset=\"training\",\n",
    "                                                      class_mode='categorical')\n",
    "\n",
    "  validation_generator = image_datagen.flow_from_directory(\n",
    "      val_path,\n",
    "      target_size=(312, 416),\n",
    "      # target_size=(224, 224),\n",
    "      batch_size=32,\n",
    "      shuffle=True,\n",
    "      # subset=\"validation\",\n",
    "      class_mode='categorical')\n",
    "\t\n",
    "\t# FIT THE MODEL\n",
    "  history = model.fit(\n",
    "    train_generator,\n",
    "    # steps_per_epoch=50,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    # validation_steps=20,\n",
    "    validation_steps=len(validation_generator))\n",
    "  \n",
    "  VALIDATION_ACCURACY.append(history.history['val_accuracy'])\n",
    "  VALIDATION_LOSS.append(history.history['val_loss'])\n",
    "  TRAINING_ACCURACY.append(history.history['accuracy'])\n",
    "  TRAINING_LOSS.append(history.history['loss'])\n",
    "\n",
    "  predictions = model.predict_generator(validation_generator, verbose=1)\n",
    "  yPredictions = np.argmax(predictions, axis=1)\n",
    "  true_classes = validation_generator.classes\n",
    "  \n",
    "  # evaluate validation performance\n",
    "  print(\"***Performance on Validation data***\")    \n",
    "  valAcc, valPrec, valFScore = my_metrics(true_classes, yPredictions)\n",
    "  \n",
    "  tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAqB0GJ7TmGl"
   },
   "source": [
    "Show chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AMNqaj9ELAf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(TRAINING_ACCURACY, label='Training Accuracy')\n",
    "plt.plot(VALIDATION_ACCURACY, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(TRAINING_LOSS, label='Training Loss')\n",
    "plt.plot(VALIDATION_LOSS, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,3.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4p1H7aCT4rt"
   },
   "source": [
    "#Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "wyW6w6lG9OVp",
    "outputId": "ff3be601-7ff5-41bc-8a5c-d0a76166b3c4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c15b2a89969c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/TA/splitdata/test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m test_generator = image_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_datagen' is not defined"
     ]
    }
   ],
   "source": [
    "test_dir = \"/content/drive/My Drive/TA/splitdata/test\"\n",
    "\n",
    "test_generator = image_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Model evaluate:\")\n",
    "results = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_feXGA4T8Bx"
   },
   "source": [
    "Show confussion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82AZDJ459RyM"
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(test_generator, len(test_generator))\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "print(cm)\n",
    "df_cm = pd.DataFrame(cm, index = test_generator.class_indices, columns = test_generator.class_indices)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, cmap=\"OrRd\")\n",
    "\n",
    "# print('Classification Report')\n",
    "# print(classification_report(test_generator.classes, y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "k_folds.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
